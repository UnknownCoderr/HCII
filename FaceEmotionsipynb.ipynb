{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 \n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import socket \n",
    "import threading\n",
    "global isConn , result\n",
    "isConn = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():   \n",
    "    soc = socket.socket()\n",
    "    global conn,isConn\n",
    "    soc.bind(('localhost',2000))\n",
    "    soc.listen(5)\n",
    "    conn , addr = soc.accept()\n",
    "    isConn = 1\n",
    "    print(\"device connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SendMess(x):\n",
    "    msg = bytes(f\"{x}\",'utf-8')\n",
    "    conn.send(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_detection():\n",
    "    connect()\n",
    "    vid = cv2.VideoCapture(1)\n",
    "    frameCounter = 0\n",
    "    while True:\n",
    "        success, frame = vid.read()\n",
    "        frameCounter += 1\n",
    "\n",
    "        if success:\n",
    "            result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "            if isinstance(result, list) and len(result) > 0:\n",
    "                first_result = result[0]\n",
    "\n",
    "                if 'region' in first_result.keys():\n",
    "                    faces = first_result['region']\n",
    "\n",
    "                    if 'x' in faces and 'y' in faces and 'w' in faces and 'h' in faces:\n",
    "                        x, y, w, h = int(faces['x']), int(faces['y']), int(faces['w']), int(faces['h'])\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                        emotion = first_result['dominant_emotion']\n",
    "                        text = f\"Emotion: {emotion}\"\n",
    "                        cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                SendMess(emotion)\n",
    "            cv2.imshow('Emotion Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device connected\n"
     ]
    }
   ],
   "source": [
    "thread2 = threading.Thread(target=emotion_detection)\n",
    "thread2.start()\n",
    "thread2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
